{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92f040a6-a8b6-4592-9dd2-aa8d8258939c",
   "metadata": {},
   "source": [
    "\n",
    "This is a dataset of Spotify tracks over a range of 125 different genres. Each track has some audio features associated with it. The data is in CSV format which is tabular and can be loaded quickly.\n",
    "\n",
    "Usage\n",
    "The dataset can be used for:\n",
    "\n",
    "1. Building a Recommendation System based on some user input or preference\n",
    "2. Classification purposes based on audio features and available genres\n",
    "3. Any other application that you can think of. Feel free to discuss!\n",
    "\n",
    "Column Description\n",
    "track_id: The Spotify ID for the track\n",
    "\n",
    "artists: The artists' names who performed the track. If there is more than one artist, they are separated by a ;\n",
    "\n",
    "album_name: The album name in which the track appears\n",
    "\n",
    "track_name: Name of the track\n",
    "\n",
    "popularity: The popularity of a track is a value between 0 and 100, with 100 being the most popular. The popularity is calculated by algorithm and is based, in the most part, on the total number of plays the track has had and how recent those plays are. Generally speaking, songs that are being played a lot now will have a higher popularity than songs that were played a lot in the past. Duplicate tracks (e.g. the same track from a single and an album) are rated independently. Artist and album popularity is derived mathematically from track popularity.\n",
    "\n",
    "duration_ms: The track length in milliseconds\n",
    "\n",
    "explicit: Whether or not the track has explicit lyrics (true = yes it does; false = no it does not OR unknown)\n",
    "\n",
    "danceability: Danceability describes how suitable a track is for dancing based on a combination of musical elements including tempo, rhythm stability, beat strength, and overall regularity. A value of 0.0 is least danceable and 1.0 is most danceable\n",
    "\n",
    "energy: Energy is a measure from 0.0 to 1.0 and represents a perceptual measure of intensity and activity. Typically, energetic tracks feel fast, loud, and noisy. For example, death metal has high energy, while a Bach prelude scores low on the scale\n",
    "\n",
    "key: The key the track is in. Integers map to pitches using standard Pitch Class notation. E.g. 0 = C, 1 = C♯/D♭, 2 = D, and so on. If no key was detected, the value is -1\n",
    "\n",
    "loudness: The overall loudness of a track in decibels (dB)\n",
    "\n",
    "mode: Mode indicates the modality (major or minor) of a track, the type of scale from which its melodic content is derived. Major is represented by 1 and minor is 0\n",
    "\n",
    "speechiness: Speechiness detects the presence of spoken words in a track. The more exclusively speech-like the recording (e.g. talk show, audio book, poetry), the closer to 1.0 the attribute value. Values above 0.66 describe tracks that are probably made entirely of spoken words. Values between 0.33 and 0.66 describe tracks that may contain both music and speech, either in sections or layered, including such cases as rap music. Values below 0.33 most likely represent music and other non-speech-like tracks\n",
    "\n",
    "acousticness: A confidence measure from 0.0 to 1.0 of whether the track is acoustic. 1.0 represents high confidence the track is acoustic\n",
    "instrumentalness: Predicts whether a track contains no vocals. \"Ooh\" and \"aah\" sounds are treated as instrumental in this context. Rap or spoken word tracks are clearly \"vocal\". The closer the instrumentalness value is to 1.0, the greater likelihood the track contains no vocal content\n",
    "\n",
    "liveness: Detects the presence of an audience in the recording. Higher liveness values represent an increased probability that the track was performed live. A value above 0.8 provides strong likelihood that the track is live\n",
    "\n",
    "valence: A measure from 0.0 to 1.0 describing the musical positiveness conveyed by a track. Tracks with high valence sound more positive (e.g. happy, cheerful, euphoric), while tracks with low valence sound more negative (e.g. sad, depressed, angry)\n",
    "\n",
    "tempo: The overall estimated tempo of a track in beats per minute (BPM). In musical terminology, tempo is the speed or pace of a given piece and derives directly from the average beat duration\n",
    "\n",
    "time_signature: An estimated time signature. The time signature (meter) is a notational convention to specify how many beats are in each bar (or measure). The time signature ranges from 3 to 7 indicating time signatures of 3/4, to 7/4.\n",
    "\n",
    "track_genre: The genre in which the track belongs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329ef1d0-9eed-481c-8234-f0fed1bb1685",
   "metadata": {},
   "source": [
    "We want recommendations : similar artists, different songs from the same artist, genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6dc48d7-49d5-49cf-8500-4a81e96431cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from surprise import Dataset, Reader, SVD\n",
    "from surprise.model_selection import train_test_split, cross_validate, GridSearchCV\n",
    "from surprise.accuracy import rmse\n",
    "from surprise import accuracy\n",
    "from surprise.prediction_algorithms import KNNWithMeans, KNNBasic, KNNBaseline\n",
    "from surprise.similarities import cosine, msd, pearson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14910def-9a16-4b0f-9532-ce90a34c76b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_id</th>\n",
       "      <th>artists</th>\n",
       "      <th>album_name</th>\n",
       "      <th>track_name</th>\n",
       "      <th>popularity</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>explicit</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>track_genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5SuOikwiRyPMVoIQDJUgSV</td>\n",
       "      <td>Gen Hoshino</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>73</td>\n",
       "      <td>230666</td>\n",
       "      <td>False</td>\n",
       "      <td>0.676</td>\n",
       "      <td>0.4610</td>\n",
       "      <td>1</td>\n",
       "      <td>-6.746</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1430</td>\n",
       "      <td>0.0322</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.3580</td>\n",
       "      <td>0.715</td>\n",
       "      <td>87.917</td>\n",
       "      <td>4</td>\n",
       "      <td>acoustic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4qPNDBW1i3p13qLCt0Ki3A</td>\n",
       "      <td>Ben Woodward</td>\n",
       "      <td>Ghost (Acoustic)</td>\n",
       "      <td>Ghost - Acoustic</td>\n",
       "      <td>55</td>\n",
       "      <td>149610</td>\n",
       "      <td>False</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.1660</td>\n",
       "      <td>1</td>\n",
       "      <td>-17.235</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0763</td>\n",
       "      <td>0.9240</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.267</td>\n",
       "      <td>77.489</td>\n",
       "      <td>4</td>\n",
       "      <td>acoustic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1iJBSr7s7jYXzM8EGcbK5b</td>\n",
       "      <td>Ingrid Michaelson;ZAYN</td>\n",
       "      <td>To Begin Again</td>\n",
       "      <td>To Begin Again</td>\n",
       "      <td>57</td>\n",
       "      <td>210826</td>\n",
       "      <td>False</td>\n",
       "      <td>0.438</td>\n",
       "      <td>0.3590</td>\n",
       "      <td>0</td>\n",
       "      <td>-9.734</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0557</td>\n",
       "      <td>0.2100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1170</td>\n",
       "      <td>0.120</td>\n",
       "      <td>76.332</td>\n",
       "      <td>4</td>\n",
       "      <td>acoustic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6lfxq3CG4xtTiEg7opyCyx</td>\n",
       "      <td>Kina Grannis</td>\n",
       "      <td>Crazy Rich Asians (Original Motion Picture Sou...</td>\n",
       "      <td>Can't Help Falling In Love</td>\n",
       "      <td>71</td>\n",
       "      <td>201933</td>\n",
       "      <td>False</td>\n",
       "      <td>0.266</td>\n",
       "      <td>0.0596</td>\n",
       "      <td>0</td>\n",
       "      <td>-18.515</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0363</td>\n",
       "      <td>0.9050</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>0.1320</td>\n",
       "      <td>0.143</td>\n",
       "      <td>181.740</td>\n",
       "      <td>3</td>\n",
       "      <td>acoustic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5vjLSffimiIP26QG5WcN2K</td>\n",
       "      <td>Chord Overstreet</td>\n",
       "      <td>Hold On</td>\n",
       "      <td>Hold On</td>\n",
       "      <td>82</td>\n",
       "      <td>198853</td>\n",
       "      <td>False</td>\n",
       "      <td>0.618</td>\n",
       "      <td>0.4430</td>\n",
       "      <td>2</td>\n",
       "      <td>-9.681</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0526</td>\n",
       "      <td>0.4690</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0829</td>\n",
       "      <td>0.167</td>\n",
       "      <td>119.949</td>\n",
       "      <td>4</td>\n",
       "      <td>acoustic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 track_id                 artists  \\\n",
       "0  5SuOikwiRyPMVoIQDJUgSV             Gen Hoshino   \n",
       "1  4qPNDBW1i3p13qLCt0Ki3A            Ben Woodward   \n",
       "2  1iJBSr7s7jYXzM8EGcbK5b  Ingrid Michaelson;ZAYN   \n",
       "3  6lfxq3CG4xtTiEg7opyCyx            Kina Grannis   \n",
       "4  5vjLSffimiIP26QG5WcN2K        Chord Overstreet   \n",
       "\n",
       "                                          album_name  \\\n",
       "0                                             Comedy   \n",
       "1                                   Ghost (Acoustic)   \n",
       "2                                     To Begin Again   \n",
       "3  Crazy Rich Asians (Original Motion Picture Sou...   \n",
       "4                                            Hold On   \n",
       "\n",
       "                   track_name  popularity  duration_ms  explicit  \\\n",
       "0                      Comedy          73       230666     False   \n",
       "1            Ghost - Acoustic          55       149610     False   \n",
       "2              To Begin Again          57       210826     False   \n",
       "3  Can't Help Falling In Love          71       201933     False   \n",
       "4                     Hold On          82       198853     False   \n",
       "\n",
       "   danceability  energy  key  loudness  mode  speechiness  acousticness  \\\n",
       "0         0.676  0.4610    1    -6.746     0       0.1430        0.0322   \n",
       "1         0.420  0.1660    1   -17.235     1       0.0763        0.9240   \n",
       "2         0.438  0.3590    0    -9.734     1       0.0557        0.2100   \n",
       "3         0.266  0.0596    0   -18.515     1       0.0363        0.9050   \n",
       "4         0.618  0.4430    2    -9.681     1       0.0526        0.4690   \n",
       "\n",
       "   instrumentalness  liveness  valence    tempo  time_signature track_genre  \n",
       "0          0.000001    0.3580    0.715   87.917               4    acoustic  \n",
       "1          0.000006    0.1010    0.267   77.489               4    acoustic  \n",
       "2          0.000000    0.1170    0.120   76.332               4    acoustic  \n",
       "3          0.000071    0.1320    0.143  181.740               3    acoustic  \n",
       "4          0.000000    0.0829    0.167  119.949               4    acoustic  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spotify_df = pd.read_csv('Data/dataset.csv', index_col = 0)\n",
    "spotify_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f23d240-2a5f-406b-b52c-7c1c86662e37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 114000 entries, 0 to 113999\n",
      "Data columns (total 20 columns):\n",
      " #   Column            Non-Null Count   Dtype  \n",
      "---  ------            --------------   -----  \n",
      " 0   track_id          114000 non-null  object \n",
      " 1   artists           113999 non-null  object \n",
      " 2   album_name        113999 non-null  object \n",
      " 3   track_name        113999 non-null  object \n",
      " 4   popularity        114000 non-null  int64  \n",
      " 5   duration_ms       114000 non-null  int64  \n",
      " 6   explicit          114000 non-null  bool   \n",
      " 7   danceability      114000 non-null  float64\n",
      " 8   energy            114000 non-null  float64\n",
      " 9   key               114000 non-null  int64  \n",
      " 10  loudness          114000 non-null  float64\n",
      " 11  mode              114000 non-null  int64  \n",
      " 12  speechiness       114000 non-null  float64\n",
      " 13  acousticness      114000 non-null  float64\n",
      " 14  instrumentalness  114000 non-null  float64\n",
      " 15  liveness          114000 non-null  float64\n",
      " 16  valence           114000 non-null  float64\n",
      " 17  tempo             114000 non-null  float64\n",
      " 18  time_signature    114000 non-null  int64  \n",
      " 19  track_genre       114000 non-null  object \n",
      "dtypes: bool(1), float64(9), int64(5), object(5)\n",
      "memory usage: 17.5+ MB\n"
     ]
    }
   ],
   "source": [
    "spotify_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85de0095-b4c4-41c5-bb53-4f274c6d5004",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "track_id            0\n",
       "artists             1\n",
       "album_name          1\n",
       "track_name          1\n",
       "popularity          0\n",
       "duration_ms         0\n",
       "explicit            0\n",
       "danceability        0\n",
       "energy              0\n",
       "key                 0\n",
       "loudness            0\n",
       "mode                0\n",
       "speechiness         0\n",
       "acousticness        0\n",
       "instrumentalness    0\n",
       "liveness            0\n",
       "valence             0\n",
       "tempo               0\n",
       "time_signature      0\n",
       "track_genre         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spotify_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c7d76f-0920-40ae-8fdc-169ee05fc4eb",
   "metadata": {},
   "source": [
    "### Check for Duplicate Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9bf27261-6ed7-4f09-9f0a-685cf556d5c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "450"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spotify_df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f18d9c-1280-4d28-9da4-4330bd7b0438",
   "metadata": {},
   "source": [
    "There are 450 identified duplicates. In this case we drop them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "412f62f0-8840-4d32-a76f-e6444f2e307f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(113550, 20)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dropping duplicates\n",
    "\n",
    "spotify_df = spotify_df.drop_duplicates()\n",
    "spotify_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2478f06-49f8-449f-8c27-daa45f196574",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>popularity</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>113550.000000</td>\n",
       "      <td>1.135500e+05</td>\n",
       "      <td>113550.000000</td>\n",
       "      <td>113550.000000</td>\n",
       "      <td>113550.000000</td>\n",
       "      <td>113550.000000</td>\n",
       "      <td>113550.000000</td>\n",
       "      <td>113550.000000</td>\n",
       "      <td>113550.000000</td>\n",
       "      <td>113550.000000</td>\n",
       "      <td>113550.000000</td>\n",
       "      <td>113550.000000</td>\n",
       "      <td>113550.000000</td>\n",
       "      <td>113550.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>33.324139</td>\n",
       "      <td>2.280794e+05</td>\n",
       "      <td>0.567031</td>\n",
       "      <td>0.642090</td>\n",
       "      <td>5.309467</td>\n",
       "      <td>-8.243419</td>\n",
       "      <td>0.637860</td>\n",
       "      <td>0.084674</td>\n",
       "      <td>0.314067</td>\n",
       "      <td>0.155702</td>\n",
       "      <td>0.213611</td>\n",
       "      <td>0.474207</td>\n",
       "      <td>122.175888</td>\n",
       "      <td>3.904218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>22.283976</td>\n",
       "      <td>1.064148e+05</td>\n",
       "      <td>0.173408</td>\n",
       "      <td>0.251052</td>\n",
       "      <td>3.560134</td>\n",
       "      <td>5.011401</td>\n",
       "      <td>0.480621</td>\n",
       "      <td>0.105761</td>\n",
       "      <td>0.331907</td>\n",
       "      <td>0.309216</td>\n",
       "      <td>0.190461</td>\n",
       "      <td>0.259204</td>\n",
       "      <td>29.972861</td>\n",
       "      <td>0.432115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-49.531000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>1.741802e+05</td>\n",
       "      <td>0.456000</td>\n",
       "      <td>0.473000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>-9.997750</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.035900</td>\n",
       "      <td>0.016800</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.098000</td>\n",
       "      <td>0.260000</td>\n",
       "      <td>99.296500</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>2.130000e+05</td>\n",
       "      <td>0.580000</td>\n",
       "      <td>0.685000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>-6.997000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.048900</td>\n",
       "      <td>0.168000</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.132000</td>\n",
       "      <td>0.464000</td>\n",
       "      <td>122.020000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>2.615878e+05</td>\n",
       "      <td>0.695000</td>\n",
       "      <td>0.854000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>-5.001000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.084500</td>\n",
       "      <td>0.596000</td>\n",
       "      <td>0.048675</td>\n",
       "      <td>0.273000</td>\n",
       "      <td>0.683000</td>\n",
       "      <td>140.073750</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>5.237295e+06</td>\n",
       "      <td>0.985000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>4.532000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.965000</td>\n",
       "      <td>0.996000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995000</td>\n",
       "      <td>243.372000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          popularity   duration_ms   danceability         energy  \\\n",
       "count  113550.000000  1.135500e+05  113550.000000  113550.000000   \n",
       "mean       33.324139  2.280794e+05       0.567031       0.642090   \n",
       "std        22.283976  1.064148e+05       0.173408       0.251052   \n",
       "min         0.000000  0.000000e+00       0.000000       0.000000   \n",
       "25%        17.000000  1.741802e+05       0.456000       0.473000   \n",
       "50%        35.000000  2.130000e+05       0.580000       0.685000   \n",
       "75%        50.000000  2.615878e+05       0.695000       0.854000   \n",
       "max       100.000000  5.237295e+06       0.985000       1.000000   \n",
       "\n",
       "                 key       loudness           mode    speechiness  \\\n",
       "count  113550.000000  113550.000000  113550.000000  113550.000000   \n",
       "mean        5.309467      -8.243419       0.637860       0.084674   \n",
       "std         3.560134       5.011401       0.480621       0.105761   \n",
       "min         0.000000     -49.531000       0.000000       0.000000   \n",
       "25%         2.000000      -9.997750       0.000000       0.035900   \n",
       "50%         5.000000      -6.997000       1.000000       0.048900   \n",
       "75%         8.000000      -5.001000       1.000000       0.084500   \n",
       "max        11.000000       4.532000       1.000000       0.965000   \n",
       "\n",
       "        acousticness  instrumentalness       liveness        valence  \\\n",
       "count  113550.000000     113550.000000  113550.000000  113550.000000   \n",
       "mean        0.314067          0.155702       0.213611       0.474207   \n",
       "std         0.331907          0.309216       0.190461       0.259204   \n",
       "min         0.000000          0.000000       0.000000       0.000000   \n",
       "25%         0.016800          0.000000       0.098000       0.260000   \n",
       "50%         0.168000          0.000041       0.132000       0.464000   \n",
       "75%         0.596000          0.048675       0.273000       0.683000   \n",
       "max         0.996000          1.000000       1.000000       0.995000   \n",
       "\n",
       "               tempo  time_signature  \n",
       "count  113550.000000   113550.000000  \n",
       "mean      122.175888        3.904218  \n",
       "std        29.972861        0.432115  \n",
       "min         0.000000        0.000000  \n",
       "25%        99.296500        4.000000  \n",
       "50%       122.020000        4.000000  \n",
       "75%       140.073750        4.000000  \n",
       "max       243.372000        5.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spotify_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061982fa-cb85-48c1-917c-456a131d62ca",
   "metadata": {},
   "source": [
    "From this preview, we notice that our numerical columns have different ranges. Therefore, we will use the Standardscaler() to normalize our data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9da7e38",
   "metadata": {},
   "source": [
    "## Preprocessing For Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72467170-e651-41f6-9ae9-1bb7096a2c56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['track_id', 'artists', 'album_name', 'track_name', 'popularity',\n",
       "       'duration_ms', 'explicit', 'danceability', 'energy', 'key', 'loudness',\n",
       "       'mode', 'speechiness', 'acousticness', 'instrumentalness', 'liveness',\n",
       "       'valence', 'tempo', 'time_signature', 'track_genre'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spotify_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aec960e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_id</th>\n",
       "      <th>artists</th>\n",
       "      <th>popularity</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>explicit</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>track_genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5SuOikwiRyPMVoIQDJUgSV</td>\n",
       "      <td>Gen Hoshino</td>\n",
       "      <td>73</td>\n",
       "      <td>230666</td>\n",
       "      <td>False</td>\n",
       "      <td>0.676</td>\n",
       "      <td>0.4610</td>\n",
       "      <td>1</td>\n",
       "      <td>-6.746</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1430</td>\n",
       "      <td>0.0322</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.3580</td>\n",
       "      <td>0.7150</td>\n",
       "      <td>87.917</td>\n",
       "      <td>acoustic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4qPNDBW1i3p13qLCt0Ki3A</td>\n",
       "      <td>Ben Woodward</td>\n",
       "      <td>55</td>\n",
       "      <td>149610</td>\n",
       "      <td>False</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.1660</td>\n",
       "      <td>1</td>\n",
       "      <td>-17.235</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0763</td>\n",
       "      <td>0.9240</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.2670</td>\n",
       "      <td>77.489</td>\n",
       "      <td>acoustic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1iJBSr7s7jYXzM8EGcbK5b</td>\n",
       "      <td>Ingrid Michaelson;ZAYN</td>\n",
       "      <td>57</td>\n",
       "      <td>210826</td>\n",
       "      <td>False</td>\n",
       "      <td>0.438</td>\n",
       "      <td>0.3590</td>\n",
       "      <td>0</td>\n",
       "      <td>-9.734</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0557</td>\n",
       "      <td>0.2100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1170</td>\n",
       "      <td>0.1200</td>\n",
       "      <td>76.332</td>\n",
       "      <td>acoustic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6lfxq3CG4xtTiEg7opyCyx</td>\n",
       "      <td>Kina Grannis</td>\n",
       "      <td>71</td>\n",
       "      <td>201933</td>\n",
       "      <td>False</td>\n",
       "      <td>0.266</td>\n",
       "      <td>0.0596</td>\n",
       "      <td>0</td>\n",
       "      <td>-18.515</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0363</td>\n",
       "      <td>0.9050</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>0.1320</td>\n",
       "      <td>0.1430</td>\n",
       "      <td>181.740</td>\n",
       "      <td>acoustic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5vjLSffimiIP26QG5WcN2K</td>\n",
       "      <td>Chord Overstreet</td>\n",
       "      <td>82</td>\n",
       "      <td>198853</td>\n",
       "      <td>False</td>\n",
       "      <td>0.618</td>\n",
       "      <td>0.4430</td>\n",
       "      <td>2</td>\n",
       "      <td>-9.681</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0526</td>\n",
       "      <td>0.4690</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0829</td>\n",
       "      <td>0.1670</td>\n",
       "      <td>119.949</td>\n",
       "      <td>acoustic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113995</th>\n",
       "      <td>2C3TZjDRiAzdyViavDJ217</td>\n",
       "      <td>Rainy Lullaby</td>\n",
       "      <td>21</td>\n",
       "      <td>384999</td>\n",
       "      <td>False</td>\n",
       "      <td>0.172</td>\n",
       "      <td>0.2350</td>\n",
       "      <td>5</td>\n",
       "      <td>-16.393</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0422</td>\n",
       "      <td>0.6400</td>\n",
       "      <td>0.928000</td>\n",
       "      <td>0.0863</td>\n",
       "      <td>0.0339</td>\n",
       "      <td>125.995</td>\n",
       "      <td>world-music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113996</th>\n",
       "      <td>1hIz5L4IB9hN3WRYPOCGPw</td>\n",
       "      <td>Rainy Lullaby</td>\n",
       "      <td>22</td>\n",
       "      <td>385000</td>\n",
       "      <td>False</td>\n",
       "      <td>0.174</td>\n",
       "      <td>0.1170</td>\n",
       "      <td>0</td>\n",
       "      <td>-18.318</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0401</td>\n",
       "      <td>0.9940</td>\n",
       "      <td>0.976000</td>\n",
       "      <td>0.1050</td>\n",
       "      <td>0.0350</td>\n",
       "      <td>85.239</td>\n",
       "      <td>world-music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113997</th>\n",
       "      <td>6x8ZfSoqDjuNa5SVP5QjvX</td>\n",
       "      <td>Cesária Evora</td>\n",
       "      <td>22</td>\n",
       "      <td>271466</td>\n",
       "      <td>False</td>\n",
       "      <td>0.629</td>\n",
       "      <td>0.3290</td>\n",
       "      <td>0</td>\n",
       "      <td>-10.895</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0420</td>\n",
       "      <td>0.8670</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0839</td>\n",
       "      <td>0.7430</td>\n",
       "      <td>132.378</td>\n",
       "      <td>world-music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113998</th>\n",
       "      <td>2e6sXL2bYv4bSz6VTdnfLs</td>\n",
       "      <td>Michael W. Smith</td>\n",
       "      <td>41</td>\n",
       "      <td>283893</td>\n",
       "      <td>False</td>\n",
       "      <td>0.587</td>\n",
       "      <td>0.5060</td>\n",
       "      <td>7</td>\n",
       "      <td>-10.889</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0297</td>\n",
       "      <td>0.3810</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.2700</td>\n",
       "      <td>0.4130</td>\n",
       "      <td>135.960</td>\n",
       "      <td>world-music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113999</th>\n",
       "      <td>2hETkH7cOfqmz3LqZDHZf5</td>\n",
       "      <td>Cesária Evora</td>\n",
       "      <td>22</td>\n",
       "      <td>241826</td>\n",
       "      <td>False</td>\n",
       "      <td>0.526</td>\n",
       "      <td>0.4870</td>\n",
       "      <td>1</td>\n",
       "      <td>-10.204</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0725</td>\n",
       "      <td>0.6810</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0893</td>\n",
       "      <td>0.7080</td>\n",
       "      <td>79.198</td>\n",
       "      <td>world-music</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>113550 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      track_id                 artists  popularity  \\\n",
       "0       5SuOikwiRyPMVoIQDJUgSV             Gen Hoshino          73   \n",
       "1       4qPNDBW1i3p13qLCt0Ki3A            Ben Woodward          55   \n",
       "2       1iJBSr7s7jYXzM8EGcbK5b  Ingrid Michaelson;ZAYN          57   \n",
       "3       6lfxq3CG4xtTiEg7opyCyx            Kina Grannis          71   \n",
       "4       5vjLSffimiIP26QG5WcN2K        Chord Overstreet          82   \n",
       "...                        ...                     ...         ...   \n",
       "113995  2C3TZjDRiAzdyViavDJ217           Rainy Lullaby          21   \n",
       "113996  1hIz5L4IB9hN3WRYPOCGPw           Rainy Lullaby          22   \n",
       "113997  6x8ZfSoqDjuNa5SVP5QjvX           Cesária Evora          22   \n",
       "113998  2e6sXL2bYv4bSz6VTdnfLs        Michael W. Smith          41   \n",
       "113999  2hETkH7cOfqmz3LqZDHZf5           Cesária Evora          22   \n",
       "\n",
       "        duration_ms  explicit  danceability  energy  key  loudness  mode  \\\n",
       "0            230666     False         0.676  0.4610    1    -6.746     0   \n",
       "1            149610     False         0.420  0.1660    1   -17.235     1   \n",
       "2            210826     False         0.438  0.3590    0    -9.734     1   \n",
       "3            201933     False         0.266  0.0596    0   -18.515     1   \n",
       "4            198853     False         0.618  0.4430    2    -9.681     1   \n",
       "...             ...       ...           ...     ...  ...       ...   ...   \n",
       "113995       384999     False         0.172  0.2350    5   -16.393     1   \n",
       "113996       385000     False         0.174  0.1170    0   -18.318     0   \n",
       "113997       271466     False         0.629  0.3290    0   -10.895     0   \n",
       "113998       283893     False         0.587  0.5060    7   -10.889     1   \n",
       "113999       241826     False         0.526  0.4870    1   -10.204     0   \n",
       "\n",
       "        speechiness  acousticness  instrumentalness  liveness  valence  \\\n",
       "0            0.1430        0.0322          0.000001    0.3580   0.7150   \n",
       "1            0.0763        0.9240          0.000006    0.1010   0.2670   \n",
       "2            0.0557        0.2100          0.000000    0.1170   0.1200   \n",
       "3            0.0363        0.9050          0.000071    0.1320   0.1430   \n",
       "4            0.0526        0.4690          0.000000    0.0829   0.1670   \n",
       "...             ...           ...               ...       ...      ...   \n",
       "113995       0.0422        0.6400          0.928000    0.0863   0.0339   \n",
       "113996       0.0401        0.9940          0.976000    0.1050   0.0350   \n",
       "113997       0.0420        0.8670          0.000000    0.0839   0.7430   \n",
       "113998       0.0297        0.3810          0.000000    0.2700   0.4130   \n",
       "113999       0.0725        0.6810          0.000000    0.0893   0.7080   \n",
       "\n",
       "          tempo  track_genre  \n",
       "0        87.917     acoustic  \n",
       "1        77.489     acoustic  \n",
       "2        76.332     acoustic  \n",
       "3       181.740     acoustic  \n",
       "4       119.949     acoustic  \n",
       "...         ...          ...  \n",
       "113995  125.995  world-music  \n",
       "113996   85.239  world-music  \n",
       "113997  132.378  world-music  \n",
       "113998  135.960  world-music  \n",
       "113999   79.198  world-music  \n",
       "\n",
       "[113550 rows x 17 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_to_drop = ['album_name', 'track_name', 'time_signature']\n",
    "filtered_spotify_df = spotify_df.drop(columns=columns_to_drop)\n",
    "filtered_spotify_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f767a4-5955-4fe7-bc5e-eec3231703e2",
   "metadata": {},
   "source": [
    "Since we do not have user-interaction data such as ratings , we are going to use popularity to simulate user interaction items. We will therefore use a MinMaxScaler to normalize our `popularity` column to a scale of 1 to 5. \n",
    "\n",
    "Moreover, we do not have `user_id` or identifier information, therefore we need to decide how we want to model user behaviour. \n",
    "1. simulate user_id using `track_genre` information - this approach works if we want to simulate users who prefer specific genres. Each genre can represent a \"user,\" and you can assume that users (genres) would interact with multiple tracks within that genre. This simulates varying preferences based on genre popularity.\n",
    "2. using `track_name` -\n",
    "3. `artists` - aims to recommend music based on specific artists. Many users have preferences for certain artists. Users might listen to multiple tracks by the same artist, leading to more interactions and data points associated with those synthetic user IDs. This also provides a more granularized approach as it may lead to more personalized recommendations.\n",
    "   >> this however, loses the genre preference information as users might prefer a mix of styles from an artist. Also, users might like various artists in the same genre and using this will  not reflect that.\n",
    "4. Combination of `artists` and `track_genre` - allows capturing a widerrange of user preferences as a user may enjoy multiple tracks from various artists across different genres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a9d4daa4-8e6a-481e-8c5f-650f22e82c82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(113550, 17)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_spotify_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bbbd0aa0-e929-4bcf-94b9-5ef7459f8573",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_id</th>\n",
       "      <th>artists</th>\n",
       "      <th>popularity</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>explicit</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>track_genre</th>\n",
       "      <th>user_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47730</th>\n",
       "      <td>6cLVxeHljKgjD1mQ75QKhp</td>\n",
       "      <td>Pitty</td>\n",
       "      <td>36</td>\n",
       "      <td>166683</td>\n",
       "      <td>False</td>\n",
       "      <td>0.431</td>\n",
       "      <td>0.768</td>\n",
       "      <td>11</td>\n",
       "      <td>-7.065</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0385</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>0.001220</td>\n",
       "      <td>0.113</td>\n",
       "      <td>0.659</td>\n",
       "      <td>82.132</td>\n",
       "      <td>hard-rock</td>\n",
       "      <td>Pitty_hard-rock</td>\n",
       "      <td>2.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96769</th>\n",
       "      <td>6PphhDw4Fa1U2TJkhejpdD</td>\n",
       "      <td>Akatu</td>\n",
       "      <td>37</td>\n",
       "      <td>105389</td>\n",
       "      <td>False</td>\n",
       "      <td>0.652</td>\n",
       "      <td>0.701</td>\n",
       "      <td>2</td>\n",
       "      <td>-8.178</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0348</td>\n",
       "      <td>0.532000</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.602</td>\n",
       "      <td>0.928</td>\n",
       "      <td>158.124</td>\n",
       "      <td>samba</td>\n",
       "      <td>Akatu_samba</td>\n",
       "      <td>2.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6993</th>\n",
       "      <td>1LL4f5D8E5sdURjuADBD8s</td>\n",
       "      <td>Carnifex</td>\n",
       "      <td>17</td>\n",
       "      <td>175906</td>\n",
       "      <td>False</td>\n",
       "      <td>0.573</td>\n",
       "      <td>0.976</td>\n",
       "      <td>1</td>\n",
       "      <td>-4.004</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1790</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.022200</td>\n",
       "      <td>0.272</td>\n",
       "      <td>0.315</td>\n",
       "      <td>114.020</td>\n",
       "      <td>black-metal</td>\n",
       "      <td>Carnifex_black-metal</td>\n",
       "      <td>1.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92786</th>\n",
       "      <td>6SesqTxqo0FlU6XlHNHKuG</td>\n",
       "      <td>The Delta Bombers</td>\n",
       "      <td>23</td>\n",
       "      <td>211213</td>\n",
       "      <td>False</td>\n",
       "      <td>0.593</td>\n",
       "      <td>0.614</td>\n",
       "      <td>8</td>\n",
       "      <td>-7.134</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0303</td>\n",
       "      <td>0.659000</td>\n",
       "      <td>0.013500</td>\n",
       "      <td>0.369</td>\n",
       "      <td>0.531</td>\n",
       "      <td>81.557</td>\n",
       "      <td>rockabilly</td>\n",
       "      <td>The Delta Bombers_rockabilly</td>\n",
       "      <td>1.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61286</th>\n",
       "      <td>2kAhqjQ6Tjsj9qUbJDs8Ih</td>\n",
       "      <td>≠ME</td>\n",
       "      <td>26</td>\n",
       "      <td>265760</td>\n",
       "      <td>False</td>\n",
       "      <td>0.535</td>\n",
       "      <td>0.685</td>\n",
       "      <td>1</td>\n",
       "      <td>-4.900</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0300</td>\n",
       "      <td>0.553000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.199</td>\n",
       "      <td>0.212</td>\n",
       "      <td>80.008</td>\n",
       "      <td>j-idol</td>\n",
       "      <td>≠ME_j-idol</td>\n",
       "      <td>2.04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     track_id            artists  popularity  duration_ms  \\\n",
       "47730  6cLVxeHljKgjD1mQ75QKhp              Pitty          36       166683   \n",
       "96769  6PphhDw4Fa1U2TJkhejpdD              Akatu          37       105389   \n",
       "6993   1LL4f5D8E5sdURjuADBD8s           Carnifex          17       175906   \n",
       "92786  6SesqTxqo0FlU6XlHNHKuG  The Delta Bombers          23       211213   \n",
       "61286  2kAhqjQ6Tjsj9qUbJDs8Ih                ≠ME          26       265760   \n",
       "\n",
       "       explicit  danceability  energy  key  loudness  mode  speechiness  \\\n",
       "47730     False         0.431   0.768   11    -7.065     0       0.0385   \n",
       "96769     False         0.652   0.701    2    -8.178     1       0.0348   \n",
       "6993      False         0.573   0.976    1    -4.004     0       0.1790   \n",
       "92786     False         0.593   0.614    8    -7.134     0       0.0303   \n",
       "61286     False         0.535   0.685    1    -4.900     0       0.0300   \n",
       "\n",
       "       acousticness  instrumentalness  liveness  valence    tempo  \\\n",
       "47730      0.000088          0.001220     0.113    0.659   82.132   \n",
       "96769      0.532000          0.000002     0.602    0.928  158.124   \n",
       "6993       0.000046          0.022200     0.272    0.315  114.020   \n",
       "92786      0.659000          0.013500     0.369    0.531   81.557   \n",
       "61286      0.553000          0.000000     0.199    0.212   80.008   \n",
       "\n",
       "       track_genre                       user_id  rating  \n",
       "47730    hard-rock               Pitty_hard-rock    2.44  \n",
       "96769        samba                   Akatu_samba    2.48  \n",
       "6993   black-metal          Carnifex_black-metal    1.68  \n",
       "92786   rockabilly  The Delta Bombers_rockabilly    1.92  \n",
       "61286       j-idol                    ≠ME_j-idol    2.04  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from surprise import Dataset, Reader, SVD, KNNBaseline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from surprise import accuracy\n",
    "from scipy.sparse import csr_matrix\n",
    "from surprise.model_selection import train_test_split\n",
    "\n",
    "filtered_spotify_df = filtered_spotify_df.sample(n=20000, random_state=42)\n",
    "# Create a combined synthetic user ID by concatenating artists and track_genre\n",
    "filtered_spotify_df['user_id'] = filtered_spotify_df['artists'] + '_' + filtered_spotify_df['track_genre']\n",
    "\n",
    "# Normalize popularity scores to fit a rating scale of 1 to 5\n",
    "scaler = MinMaxScaler(feature_range=(1, 5))\n",
    "filtered_spotify_df['rating'] = scaler.fit_transform(filtered_spotify_df[['popularity']])\n",
    "\n",
    "# Check for NaN values and drop them if necessary\n",
    "filtered_spotify_df.dropna(subset=['user_id', 'track_id', 'rating'], inplace=True)\n",
    "\n",
    "\n",
    "# Define the Reader and load the data\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "data = Dataset.load_from_df(filtered_spotify_df[['user_id', 'track_id', 'rating']], reader)\n",
    "\n",
    "\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "trainset, testset = train_test_split(data, test_size=0.2)\n",
    "\n",
    "# Display the first few rows of the filtered DataFrame for verification\n",
    "filtered_spotify_df.head()\n",
    "# filtered_spotify_df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d04fd70b-21f9-42e5-87b7-d4c8cc27e2b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique users: 12361, Unique tracks: 19000\n"
     ]
    }
   ],
   "source": [
    "unique_users = filtered_spotify_df['user_id'].nunique()\n",
    "unique_tracks = filtered_spotify_df['track_id'].nunique()\n",
    "print(f'Unique users: {unique_users}, Unique tracks: {unique_tracks}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a15147-3458-4eaf-841e-f1a57ce7063b",
   "metadata": {},
   "source": [
    "There were some missing values in our `user_id` and `track_id` columns. We drop them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b63ed43a-0c5a-431c-a079-2fdd6751c247",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and test sets\n",
    "# trainset, testset = train_test_split(data, test_size=0.2)\n",
    "\n",
    "# # Get the training set as a list of tuples\n",
    "# trainset_data = [(trainset.to_raw_uid(u), trainset.to_raw_iid(i), r) \n",
    "#                  for (u, i, r) in trainset.all_ratings()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e392b84-72e9-46ed-87f4-ab6bb9d2a69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame\n",
    "# trainset_df = pd.DataFrame(trainset_data, columns=['user_id', 'track_id', 'rating'])\n",
    "# trainset_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63694fc-21db-4956-b575-cd0f36dd515e",
   "metadata": {},
   "source": [
    "### Model 1 - KNNBaseline \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "552d1104-4518-4dc3-9f9d-0efd1e6d8d86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    }
   ],
   "source": [
    "from surprise import Dataset, Reader, accuracy\n",
    "from surprise.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Step 1: Prepare your DataFrame (Assuming 'filtered_spotify_df' is your DataFrame)\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "data = Dataset.load_from_df(filtered_spotify_df[['user_id', 'track_id', 'rating']], reader)\n",
    "\n",
    "# Step 2: Split the data into training and test sets\n",
    "trainset, testset = train_test_split(data, test_size=0.2)\n",
    "\n",
    "# Step 3: Define your model and parameter grid\n",
    "param_grid = {\n",
    "    'k': [5, 10, 15, 20],\n",
    "    'min_k': [1, 5],\n",
    "    'sim_options': {\n",
    "        'name': ['cosine', 'pearson'],\n",
    "        'user_based': [True, False]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Step 4: Perform grid search for KNNBaseline\n",
    "grid_search_knn = GridSearchCV(KNNBaseline, param_grid, measures=['rmse'], cv=3)\n",
    "grid_search_knn.fit(data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "403f2b24-44c2-48de-9965-c535c57c4320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 0.0127\n",
      "Best KNN Model Parameters: {'k': 5, 'min_k': 1, 'sim_options': {'name': 'cosine', 'user_based': True}}\n",
      "Training RMSE: 0.0127\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Get the best KNN model\n",
    "best_knn_model = grid_search_knn.best_estimator['rmse']\n",
    "\n",
    "# Step 6: Fit the best model to the training set\n",
    "best_knn_model.fit(trainset)\n",
    "\n",
    "# Step 7: Predict ratings for the training set\n",
    "# You can use the test method on the trainset\n",
    "train_predictions = best_knn_model.test(trainset.build_testset())\n",
    "\n",
    "# Step 8: Calculate RMSE for the training set predictions\n",
    "train_rmse = accuracy.rmse(train_predictions)\n",
    "\n",
    "# # Step 9: Predict ratings for the test set\n",
    "# test_predictions = best_knn_model.test(testset)\n",
    "\n",
    "# Step 10: Calculate RMSE for the test set predictions\n",
    "# test_rmse = accuracy.rmse(test_predictions)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Best KNN Model Parameters: {grid_search_knn.best_params['rmse']}\")\n",
    "print(f\"Training RMSE: {train_rmse:.4f}\")\n",
    "# print(f\"Test RMSE: {test_rmse:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a6b0df-78fd-4cae-8d87-684e8039c90d",
   "metadata": {},
   "source": [
    "### Model 2 - SVD algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c6b9a05a-054e-494c-9c20-9f64a1f6d2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Define parameter grid for SVD\n",
    "param_grid = {\n",
    "    'n_factors': [50, 100, 150],  # Number of latent factors\n",
    "    'n_epochs': [20, 30, 40],     # Number of epochs\n",
    "    'lr_all': [0.005, 0.01],      # Learning rate for all parameters\n",
    "    'reg_all': [0.02, 0.1],       # Regularization term\n",
    "}\n",
    "\n",
    "# Step 4: Perform grid search for SVD\n",
    "grid_search_svd = GridSearchCV(SVD, param_grid, measures=['rmse'], cv=5)\n",
    "grid_search_svd.fit(data)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d6713410-46ec-4ad4-b235-3c11e6e31691",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Get the best SVD model\n",
    "best_svd_model = grid_search_svd.best_estimator['rmse']\n",
    "\n",
    "# Step 6: Fit the best model to the training set\n",
    "best_svd_model.fit(trainset)\n",
    "\n",
    "# Step 7: Predict ratings for the training set\n",
    "train_predictions = best_svd_model.test(trainset.build_testset())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "75460c19-61b6-4dd8-a9e2-05da8d86178e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.2288\n",
      "Best SVD Model Parameters: {'n_factors': 50, 'n_epochs': 40, 'lr_all': 0.01, 'reg_all': 0.02}\n",
      "Training RMSE: 0.2288\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 8: Calculate RMSE for the training set predictions\n",
    "train_rmse = accuracy.rmse(train_predictions)\n",
    "\n",
    "# Step 9: Predict ratings for the test set\n",
    "# test_predictions = best_svd_model.test(testset)\n",
    "\n",
    "# Step 10: Calculate RMSE for the test set predictions\n",
    "# test_rmse = accuracy.rmse(test_predictions)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Best SVD Model Parameters: {grid_search_svd.best_params['rmse']}\")\n",
    "print(f\"Training RMSE: {train_rmse:.4f}\")\n",
    "# print(f\"Test RMSE: {test_rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee8a9fe-aa57-4f04-9684-09ed073bb542",
   "metadata": {},
   "source": [
    "The SVD model rmse is  slightly higher as compared to the KNNBaseline model. The KNNBaseline model still performs better than the SVD algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d8ad8b29-eb70-4dd2-a8e9-f11605b99b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "numerical_features = filtered_spotify_df.select_dtypes(include=['float64', 'int64']).columns\n",
    "categorical_features = filtered_spotify_df.select_dtypes(include=['object']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43513544",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f53fefb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_transformer = Pipeline(steps=[('scaler', StandardScaler())])\n",
    "\n",
    "# transform categorical data\n",
    "categorical_transformer = Pipeline(steps=[('ohe', OneHotEncoder(handle_unknown='ignore'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dba21eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine steps using columnTransformer\n",
    "preprocessor = ColumnTransformer(transformers= [\n",
    "    ('num', numerical_transformer, numerical_features),\n",
    "    ('cat', categorical_transformer, categorical_features)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6016d891",
   "metadata": {},
   "outputs": [],
   "source": [
    "# full pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4dbf832d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply pipeline to full df\n",
    "spotify_processed = pipeline.fit_transform(spotify_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
